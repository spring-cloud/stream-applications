# Debezium Auto-Configuration

This module provides a generic https://debezium.io/documentation/reference/2.2/development/engine.html[DebeziumEngine.Builder] auto-configuration that can be reused and composed in other applications.

NOTE: `DebeziumEngine` doesn't not required Kafka or Kafka Connect as it runs embedded inside your application. This approach though comes with some delivery guarantee limitations as explained https://debezium.io/documentation/reference/2.2/development/engine.html#_handling_failures[here].

The `Debezium Engine` is a https://en.wikipedia.org/wiki/Change_data_capture[Change Data Capture] (CDC) utility, that allows *capturing* database change events and process them with custom `java.util.Consumer` or `io.debezium.engine.ChangeConsumer` event handler implementations. The `java.util.Consumer` allow element-wise change event processing while the `ChangeConsumer` permits batch event processing.

The `DebeziumEngine.Builder` auto-configuration is activated only if a Debezium Connector is found on the classpath and the `debezium.properties.connector.class` property is set.

To process the incoming database change events you need to include the Debezium `auto-configuration` dependency to your project:

====
[source, xml, subs="normal", role="primary"]
.Maven
----
<dependency>
    <groupId>org.springframework.cloud.fn</groupId>
    <artifactId>debezium-autoconfigure</artifactId>
    <version>{project-version}</version>
</dependency>
----
[source, groovy, subs="normal", role="secondary"]
.Gradle
----
compile "org.springframework.cloud.fn:debezium-autoconfigure:{project-version}"
----
====

As well as the https://debezium.io/documentation/reference/2.2/connectors/index.html[debezium connector] dependency for the Database the data is received from.
For example for PostgreSQL the postgres debezium connector dependency is:

====
[source, xml, subs="normal", role="primary"]
.Maven
----
<dependency>
    <groupId>io.debezium</groupId>
    <artifactId>debezium-connector-postgres</artifactId>
    <version>${debezium-version}</version>
</dependency>

----
[source, groovy, subs="normal", role="secondary"]
.Gradle
----
compile "io.debezium:debezium-connector-postgres:{debezium-version}"
----
====


Then implement your own `java.util.Consumer<ChangeEvent>` (or `ChangeConsumer<ChangeEvent>`) handler bean and wire it into a DebeziumEngine instance. For example:

[source, java]
----
	@Bean
	public Consumer<ChangeEvent<byte[], byte[]>> customConsumer() { // <1>
		return new Consumer<ChangeEvent<byte[], byte[]>>() {
			@Override
			public void accept(ChangeEvent<byte[], byte[]> changeEvent) {
				if (changeEvent != null) { // ignore null records
					System.out.println("Key:" + changeEvent.key() + ", Value: " changeEvent.value());
				}
			}
		}
	}

	@Bean
	public DebeziumEngine<ChangeEvent<byte[], byte[]>> debeziumEngine( // <2>
			Consumer<ChangeEvent<byte[], byte[]>> consumer,
			DebeziumEngine.Builder<ChangeEvent<byte[], byte[]>> builder) {

		return new builder.notifying(consumer).build();
	}

	@Bean
	public EmbeddedEngineExecutorService embeddedEngine( // <3>
			DebeziumEngine<ChangeEvent<byte[], byte[]>> debeziumEngine) {
		return new EmbeddedEngineExecutorService(debeziumEngine);
	}
----
<1> Create a custom change event consumer.
<2> Use the debezium builder provided from the auto-configuration and the custom consumer to create new DebeziumEngin instance.
<3> The DebeziumEngine is designed to be submitted to an `Executor` or `ExecutorService` for execution.
The `EmbeddedEngineExecutorService` is handy `ExecutorService` implementation that aligns with the Spring lifecycle.
But the `EmbeddedEngineExecutorService` is optional.
Usually the debezium auto-configuration client would provide its own executors better aligned with their implementation lifecycles.
For example the `DebeziumReactiveConsumerConfiguration` embeds an ExecutorService as part of the
`Supplier<Flux<Message<?>>>` configuration.

## Configuration Options

$$debezium.header-format$$:: `ChangeEvent` header format. *($$DebeziumFormat$$, default: `JSON`, possible values: `JSON`,`AVRO`,`PROTOBUF`)*
$$debezium.payload-format$$:: `ChangeEvent` Key and Payload formats. *($$DebeziumFormat$$, default: `JSON`, possible values: `JSON`,`AVRO`,`PROTOBUF`)*
$$debezium.offset-commit-policy$$:: The policy that defines when the offsets should be committed to offset storage. *($$DebeziumOffsetCommitPolicy$$, default: `PERIODIC`, possible values: `ALWAYS`,`PERIODIC`,`DEFAULT`)*
$$debezium.properties$$:: $$Spring pass-trough wrapper for debezium configuration properties. All properties with a `debezium.properties.*` prefix are native Debezium properties.$$ *($$Map<String, String>$$, default: `$$<none>$$`)*
For example the `debezium.properties.connector.class` property is converted into `connector.class` before provided to the DebeziumEngine.

Here is a sample configuration for the sample snipped above:

[source, bash]
----
debezium.properties.connector.class=io.debezium.connector.mysql.MySqlConnector # <1>
debezium.properties.database.user=debezium # <2>
debezium.properties.database.password=dbz # <2>
debezium.properties.database.hostname=localhost # <2>
debezium.properties.database.port=3306 # <2>

debezium.properties.database.server.id=85744 # <3>
debezium.properties.database.server.name=my-app-connector # <3>
debezium.properties.topic.prefix=my-topic # <3>
debezium.properties.name=my-sql-connector # <3>

debezium.properties.key.converter.schemas.enable=true # <4>
debezium.properties.value.converter.schemas.enable=true # <4>

debezium.properties.offset.flush.interval.ms=60000

debezium.properties.database.history=io.debezium.relational.history.MemoryDatabaseHistory # <5>
debezium.properties.schema.history.internal=io.debezium.relational.history.MemorySchemaHistory # <5>
debezium.properties.offset.storage=org.apache.kafka.connect.storage.MemoryOffsetBackingStore # <5>

----
<1> Configures the Debezium Engine to use https://debezium.io/docs/connectors/mysql/[MySqlConnector].
<2> Connection to the MySQL server running on `localhost:3306` as `debezium` user.
<3> Metadata used to identify and dispatch the incoming events.
<4> Includes the https://debezium.io/docs/connectors/mysql/#change-events-value[Change Event Value] schema in the `ChangeEvent` message.
<5> Metadata stores to preserver the debezium state between multiple starts.

### Connectors properties

The table below lists all available Debezium properties for each connecter.

.Table of the native Debezium configuration properties for every connector.
|===
| Connector | Connector properties

|https://debezium.io/documentation/reference/2.2/connectors/mysql.html[MySQL]
|https://debezium.io/documentation/reference/2.2/connectors/mysql.html#mysql-connector-properties

|https://debezium.io/documentation/reference/2.2/connectors/mongodb.html[MongoDB]
|https://debezium.io/documentation/reference/2.2/connectors/mongodb.html#mongodb-connector-properties

|https://debezium.io/documentation/reference/2.2/connectors/postgresql.html[PostgreSQL]
|https://debezium.io/documentation/reference/2.2/connectors/postgresql.html#postgresql-connector-properties

|https://debezium.io/documentation/reference/2.2/connectors/oracle.html[Oracle]
|https://debezium.io/documentation/reference/2.2/connectors/oracle.html#oracle-connector-properties

|https://debezium.io/documentation/reference/2.2/connectors/sqlserver.html[SQL Server]
|https://debezium.io/documentation/reference/2.2/connectors/sqlserver.html#sqlserver-connector-properties

|https://debezium.io/documentation/reference/2.2/connectors/db2.html[DB2]
|https://debezium.io/documentation/reference/2.2/connectors/db2.html#db2-connector-properties

|https://debezium.io/documentation/reference/2.2/connectors/vitess.html[Vitess]
|https://debezium.io/documentation/reference/2.2/connectors/vitess.html#vitess-connector-properties

|https://debezium.io/documentation/reference/2.2/connectors/spanner.html[Spanner]
|https://debezium.io/documentation/reference/2.2/connectors/spanner.html#spanner-connector-properties

|===

### Streaming vs Batching

If you register a `java.util.Consumer<ChangeEvent>` with the `DebeziumEngine.Builder` then the incoming events will processed element-wise, one by one in the order of their occurrence.
If you opt for the `io.debezium.engineChangeConsumer<ChangeEvent>` you will be allowed to process batch of events in one go, acknowledging their processing once that's done.

### Additional Configuration Components

The Debezium builder auto-configuration provides an opinionated implementation for the following configurable components:

 - `OffsetCommitPolicy` - Commit policy type. The default is a periodic commit policy based upon time intervals.
 - `Clock` - Clock needing to determine the current time.
 Defaults to the `Clock#systemDefaultZone()` system clock.
- `CompletionCallback` - callback called by the engine on `DebeziumEngine#run()` method completes with the results.
By default logs the completion status.
- `ConnectorCallback` - During the engine run, provides feedback about the the completion state of each component running within the engine (connectors, tasks etc).
By default logs the connector state.

You can override any of the above components. Just provide your `@Bean` implementation to the application context.

### Event Flattening

Debezium provides a comprehensive message format, that accurately details information about changes that happen in the system.
Sometime this format, though,  might not be suitable for the downstream consumers, that might require messages that are formatted so that field names and values are presented in a simplified, `flattened` structure.

To simplify the format of the event records that the Debezium connectors produce, you can use the https://debezium.io/documentation/reference/stable/transformations/event-flattening.html[Debezium event flattening] message transformation.
Using the https://debezium.io/documentation/reference/stable/transformations/event-flattening.html#_configuration[flattering configuration] you can configure simple messages format like this:

[source, bash]
----
--debezium.properties.transforms=unwrap
--debezium.properties.transforms.unwrap.type=io.debezium.transforms.ExtractNewRecordState
--debezium.properties.transforms.unwrap.drop.tombstones=false
--debezium.properties.transforms.unwrap.delete.handling.mode=rewrite
--debezium.properties.transforms.unwrap.add.fields=name,db
----

### Offset Storages

When a Debezium source runs, it reads information from the source and periodically records `offsets` that define how much of that information it has processed.
Should the source be restarted, it will use the last recorded offset to know where in the source information it should resume reading.
Out of the box, the following https://debezium.io/documentation/reference/2.2/development/engine.html#engine-properties[offset storage configuration] options are provided:

- In-Memory

   Doesn't persist the offset data but keeps it in memory. Therefore all offsets are lost on debezium source restart.
[source, bash]
----
--debezium.properties.offset.storage=org.apache.kafka.connect.storage.MemoryOffsetBackingStore
----

- Local Filesystem

  Store the offsets in a file on the local file system (the file can be named anything and stored anywhere). Additionally, although the connector records the offsets with every source record it produces, the engine flushes the offsets to the backing store periodically (in the example below, once each minute).
[source, bash]
----
--debezium.properties.offset.storage=org.apache.kafka.connect.storage.FileOffsetBackingStore
--debezium.properties.offset.storage.file.filename=/tmp/offsets.dat # <1>
--debezium.properties.offset.flush.interval.ms=60000 # <2>
----
<1> Path to file where offsets are to be stored. Required when `offset.storage`` is set to the `FileOffsetBackingStore`.
<2> Interval at which to try committing offsets. The default is 1 minute.

- Kafka topic

  Uses a Kafka topic to store offset data.
[source, bash]
----
--debezium.properties.offset.storage=org.apache.kafka.connect.storage.KafkaOffsetBackingStore
--debezium.properties.offset.storage.topic=my-kafka-offset-topic # <1>
--debezium.properties.offset.storage.partitions=2 # <2>
--debezium.properties.offset.storage.replication.factor=1 # <3>
--debezium.properties.offset.flush.interval.ms=60000 # <4>
----
<1> The name of the Kafka topic where offsets are to be stored. Required when `offset.storage` is set to the `KafkaOffsetBackingStore`.
<2> The number of partitions used when creating the offset storage topic.
<3> Replication factor used when creating the offset storage topic.
<4> Interval at which to try committing offsets. The default is 1 minute.

One can implement the `org.apache.kafka.connect.storage.OffsetBackingStore` interface in to provide a offset storage bound to a custom backend key-value store.

## Tests

See this link:org/springframework/cloud/fn/common/debezium/DebeziumEngineBuilderAutoConfigurationIntegrationTest.java[test suite] for how to use the auto-configuration with custom Consumer.

## Other usage

- See the https://github.com/spring-cloud/stream-applications/blob/master/functions/supplier/debezium-source/debezium-supplier[debezium-supplier] implementation about how to implement reactive consumer on top of the debezium auto-configuration.
- See this https://github.com/spring-cloud/stream-applications/blob/master/applications/source/debezium-source/README.adoc[debezium-source] about how the debezium auto-configuration and supplier are used to create a Spring Cloud Stream applications.
- See the https://docs.spring.io/spring-integration/docs/6.2.0-SNAPSHOT/reference/html/debezium.html#debezium[Spring Integration Debezium support] about how to initialize Inbound Debezium Channel Adapter with `DebeziumEngine.Builder<ChangeEvent<byte[], byte[]>>` provided by the auto-configuration.