//tag::ref-doc[]
:image-root: https://raw.githubusercontent.com/spring-cloud-stream-app-starters/tensorflow/master/images

= Image Recognition Processor

A processor that uses an https://github.com/tensorflow/models/tree/master/inception[Inception model] to classify
in real-time images into different categories (e.g. labels).

Model implements a deep https://en.wikipedia.org/wiki/Convolutional_neural_network[Convolutional Neural Network] that can achieve reasonable performance on hard visual recognition tasks
- matching or exceeding human performance in some domains like https://www.tensorflow.org/tutorials/image_recognition[image recognition].

The input of the model is an image as binary array.

The output is a JSON message in this format:

```json
{
  "labels" : [
     {"giant panda":0.98649305}
  ]
}
```
Result contains the name of the recognized category (e.g. label) along with the confidence (e.g. confidence) that the image represents this category.

If the `response-seize` is set to value higher then 1, then the result will include the top `response-seize` probable labels. For example `response-size=3` would return:

```json
{
  "labels": [
    {"giant panda":0.98649305},
    {"badger":0.010562794},
    {"ice bear":0.001130851}
  ]
}
```

=== Payload

If the incoming type is `byte[]` and the content type is set to `application/octet-stream` , then the application process the input `byte[]` image into and outputs augmented `byte[]` image payload and json header.

== Options

//tag::configuration-properties[]
$$image.recognition.cache-model$$:: $$cache the pre-trained tensorflow model.$$ *($$Boolean$$, default: `$$true$$`)*
$$image.recognition.debug-output$$:: $$<documentation missing>$$ *($$Boolean$$, default: `$$false$$`)*
$$image.recognition.debug-output-path$$:: $$<documentation missing>$$ *($$String$$, default: `$$image-recognition-result.png$$`)*
$$image.recognition.model$$:: $$pre-trained tensorflow image recognition model. Note that the model must match the selected model type!$$ *($$String$$, default: `$$https://storage.googleapis.com/mobilenet_v2/checkpoints/mobilenet_v2_1.4_224.tgz#mobilenet_v2_1.4_224_frozen.pb$$`)*
$$image.recognition.model-type$$:: $$Supports three different pre-trained tensorflow image recognition models: Inception, MobileNetV1 and MobileNetV2 1. Inception graph uses 'input' as input and 'output' as output. 2. MobileNetV2 pre-trained models: https://github.com/tensorflow/models/tree/master/research/slim/nets/mobilenet#pretrained-models 	 - normalized image size is always square (e.g. H=W) 	 - graph uses 'input' as input and 'MobilenetV2/Predictions/Reshape_1' as output.  3. MobileNetV1 pre-trained models: https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet_v1.md#pre-trained-models 	 - graph uses 'input' as input and 'MobilenetV1/Predictions/Reshape_1' as output.$$ *($$ModelType$$, default: `$$<none>$$`, possible values: `inception`,`mobilenetv1`,`mobilenetv2`)*
$$image.recognition.normalized-image-size$$:: $$Normalized image size.$$ *($$Integer$$, default: `$$224$$`)*
$$image.recognition.response-size$$:: $$number of recognized images.$$ *($$Integer$$, default: `$$5$$`)*
//end::configuration-properties[]

//end::ref-doc[]
